\setlength{\parindent}{2em}当前的目标识别方法基本上都使用了机器学习的方法。为了提高这些方法的性能，我们可以收集更多的数据，学习得到更加强大的模型，用更好的方法来防止过拟合。直到现在，有标签的数据集都是比较小的，一般只有万张的数量级（如NORB[16]，Caltech-101/256[8,9]，以及CIFAR-10/100[12]）。在这个大小的数据集上，可以很好的解决简单的识别任务，尤其是在通过标签保留变换进行数据增强的情况下。例如，目前在MNIST数据集上面数字识别最小的误差率(<0.3\%)已经接近了人类的水平[4]。但是现实世界中的目标呈现出很大的可变性，所以要去学习识别他们就需要使用更大的训练数据集。实际上，人们也已广泛地认识到小的图像数据集的缺点（如Pinto等[21]），但直到最近，才能够收集到包含数百万图像的带标签数据集。这些新的大型数据集包括LabelMe[23]（包含数十万张被完全分割的图片），ImageNet[6]（由1500万张被标记的高清图片组成，覆盖了2.2万个类别）\\

\setlength{\parindent}{2em}为了从数百万张图片中学习到数千种目标，我们需要一个学习能力极强的模型。然而，物体识别任务极高的复杂度意味着即使拥有ImageNet这么大的数据集，这个问题也很难被具体化。所以我们也需要大量关于模型的先验知识去弥补我们缺失的数据。卷积神经网络（CNNs）是一种这样的模型[16,11,13,18,15,22,26]。他们的学习能力可以通过控制网络的深度和宽度来调整，他们也可以对图像的本质做出强大且基本准确的假设(也就是说，统计上的稳定性，以及像素依赖的局部性)。因此，与相似大小的标准前馈神经网络相比，CNNs的连接和参数更少，所以更易训练，而他们理论上的最佳性能仅比标准前馈神经网络稍差一点。\\

\setlength{\parindent}{2em}尽管CNNs有很好的质量，和更有效率的局部结构，但将他们大规模的应用到高分辨率的图像中仍然需要付出高昂的代价。幸运的是，当前的GPU搭配上高度优化的2D卷积实现，已经足够强大到去加速大型CNNs的训练过程，并且最近的数据集例如ImageNet已经包含足够的有标签样本，能够训练出不会严重过拟合的模型。\\

\setlength{\parindent}{2em}本文的具体贡献如下：我们在ImageNet的子集ILSVRC-2010与ILSVRC-2012[2]上训练了到目前为止最大的卷积神经网络之一，并且在这个数据集上达到了迄今为止最好的结果。我们编写了高度优化的2D卷积GPU实现，以及其他所有训练卷积神经网络的固有操作，这些都已经公开。我们的神经网络包含一系列新的与众不同的特征，这提高了它的性能，也减少了训练时间，具体情况会在第三节介绍。即使我们拥有120万的标签样本，我们网络巨大的体积也使得过拟合成为了一个严重的问题，所以我们使用了一系列有效的技术去防止过拟合，具体情况会在第四节介绍。我们最终的神经网络包含5个卷积层和3个全连接层，这个深度似乎是很重要的：我们发现去掉任意一个卷积层（每一层包含的参数个数不超过整个模型参数个数的1\%）都会导致更差的表现。\\

\setlength{\parindent}{2em}最后，网络的大小主要受限于目前GPU的内存大小和我们愿意忍受的训练时长。我们的网络在两块GTX 580 3GB的GPU上训练了五六天。我们所有的实验都表明，只要等到更快的GPU和更大的数据集出现，其结果就可以进一步被提高。\\
