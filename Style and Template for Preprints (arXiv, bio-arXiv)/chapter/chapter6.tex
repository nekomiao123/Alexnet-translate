我们将ILSVRC-2010测试集上的结果概括为表1。我们的网络实现了top-1测试集误差率为37.5\%，top-5测试集误差率为17.0\%$\footnote{如第4.1节所述，没有对10个patches进行求平均，则预测的错误率分别为39.0％和18.3％。}$。在ILSVRC-2010竞赛中的最佳结果是47.1\%与28.2\%，，它们的方法是用不同特征训练六个sparse-coding模型，对这些模型产生的预测求平均值。从那之后公布的最好结果是45.7\%和25.7\%，它们的方法是从两类密集采样的特征中计算出费舍尔向量（FV），用费舍尔向量训练两个分类器，再对这两个分类器的预测求平均值[24]。\\
\begin{table}
  \centering
  \begin{tabular}{lll}
    \toprule
    \textbf{Model}     & \textbf{Top-1}      &\textbf{Top-5}  \\
    \midrule
    \emph{Sparse coding [2] } & \emph{47.1\%}   & \emph{28.2\%}      \\
    \emph{SIFT + FVs [24]}      & \emph{45.7\%} & \emph{20.7\%}     \\
    CNN     & \textbf{37.5\%}       & \textbf{17.0\%}  \\
    \bottomrule
  \end{tabular}
  \caption{ILSVRC-2010测试集上的结果比较。斜体字是他人取得的最好结果。}
  \label{tab:table}
\end{table}

我们也使用我们的模型参加了ILSVRC-2012竞赛，并在表2中写出了结果。因为ILSVRC-2012的测试集标签是不对外公开的，我们无法报告我们尝试的所有模型的测试误差率。在这段的剩余部分，我们将验证误差率和测试误差率互换，因为根据我们的经验，它们之间不会相差超过0.1\%（见表2）。本文描述的CNN取得了18.2\%的top-5误差率。五个类似的CNN预测的平均误差率为16.4\%。为了对ImageNet 在2011秋季发布的整个数据集（1500万张图片，22000个类别）进行分类，我们在最后的池化层之后增加了一个额外的第六层卷积层，训练了一个新的CNN，然后对它进行“fine-tuning”，最后在ILSVRC-2012上取得了16.6\%的错误率。对在ImageNet 2011秋季发布的整个数据集上预训练的两个CNN和前面提到的五个CNN的预测进行平均得到了15.3\%的错误率。第二名的成绩是26.2\%的误差率，它的方法是从不同类密集采样的特征中计算FV，用FV训练几个分类器，再对这几个分类器的预测求平均值[7]。\\
\begin{table}
  \centering
  \begin{tabular}{llll}
    \toprule
    \textbf{Model} & \textbf{Top-1(val)} &\textbf{Top-5(val)} & \textbf{Top-5(test)}\\
    \midrule
    \emph{SIFT + FVs [7]} &  —   &   —  &  \emph{26.2\%} \\
    1CNN     & 40.7\% & 18.2\%   &       —           \\
    5CNNs    & 38.1\% & 16.4\%   &\textbf{16.4\%}  \\
	1CNN*    & 39.0\% & 16.6\%   &   —  \\
	7CNNs*   & 36.7\% & 15.4\%   &\textbf{15.3\%}\\
    \bottomrule
  \end{tabular}
  \caption{ILSVRC-2010测试集上的结果比较。斜体字是他人取得的最好结果。}
  \label{tab:table}
\end{table}


最后，我们也报告了我们在ImageNet 2009秋季数据集上的误差率，ImageNet 2009秋季数据集有10,184个类，890万图像。在这个数据集上，按照惯例，我们用一半的图像来训练，一半的图像来测试。由于没有明确的测试集，我们的划分必然不同于以前作者的数据集划分，但这不会明显的影响到结果。我们在这个数据集上的的top-1和top-5错误率是67.4\%和40.9\%，使用的是上面描述的在最后的池化层之后有一个额外的第6卷积层网络。该数据集上公布的最佳结果是78.1\%和60.9\%[19]。\\

